{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we are going to improve our codes in PattRecClasses and implement forward algorithm inside MarkovChain code as well as functions such as logprob and prob in Guassian in order to generate proper input values for forward algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PattRecClasses.HMM_TA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5ddf9fa7e826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPattRecClasses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHMM_TA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# For the code to work you might have to pip install scipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Local/Pattern-Recognition-Project/PattRecClasses/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mPx_calc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgauss_logprob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mHMM_TA\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHMM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PattRecClasses.HMM_TA'"
     ]
    }
   ],
   "source": [
    "from PattRecClasses import HMM_TA \n",
    "import scipy.stats\n",
    "from matplotlib import pyplot as plt\n",
    "# For the code to work you might have to pip install scipy\n",
    "\n",
    "from CharacterFeatureExtractor import featureExtractor\n",
    "from DrawCharacter import DrawCharacter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Multivariate Gaussian Distribution Class\n",
    "'''\n",
    "class multigaussD:\n",
    "    mean = np.array([0])\n",
    "    cov = np.array([[0]])\n",
    "    def __init__(self, mu, C):\n",
    "        if C.shape[0] is not C.shape[1]:\n",
    "            print(\"error, non-square covariance matrix supplied\")\n",
    "            return\n",
    "        if mu.shape[0] is not C.shape[0]:\n",
    "            print(\"error, mismatched mean vector and covariance matrix dimensions\")\n",
    "            return\n",
    "        self.mean = mu\n",
    "        if np.where(np.diag(C)==0)[0].shape[0] != 0:\n",
    "            C += np.diagflat(np.ones(C.shape[0])/10000)\n",
    "        C[np.isnan(C)]=1\n",
    "        self.cov = C\n",
    "        return\n",
    "    def random(self, num):\n",
    "        return np.random.multivariate_normal(self.mean, self.cov, num)\n",
    "    def rand(self):\n",
    "        return np.random.multivariate_normal(self.mean, self.cov, 1)[0]\n",
    "    def likelihood(self, X):\n",
    "        p = scipy.stats.multivariate_normal(self.mean, self.cov, 1)\n",
    "        pd = p.pdf(X)\n",
    "        return pd\n",
    "    def loghood(self, X):\n",
    "        return np.log(self.likelihood(X))\n",
    "    def getmean(self):\n",
    "        return self.mean\n",
    "    def getcov(self):\n",
    "        return self.cov\n",
    "    \n",
    "def prob(x, B):\n",
    "    T = x.shape[0]\n",
    "    N = B.shape[0]\n",
    "    res = np.zeros((T, N))\n",
    "    for i in range(T):\n",
    "        for j in range(N):\n",
    "            res[i,j] = B[j].likelihood(x[i])\n",
    "    scaled = np.zeros(res.shape)\n",
    "    for i in range(scaled.shape[0]):\n",
    "        for j in range(scaled.shape[1]):\n",
    "            scaled[i, j] = res[i,j]/np.amax(res[i])\n",
    "    return res, scaled\n",
    "\n",
    "\n",
    "def logprob(x, B):\n",
    "    res, scaled = prob(x,B)\n",
    "    return np.log(res), np.log(scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data prep\n",
    "db_name = \"database_test\"\n",
    "data_features = pd.read_pickle(r'data/'+db_name+'_features.cdb')\n",
    "data_labels = pd.read_pickle(r'data/'+db_name+'_labels.cdb')\n",
    "\n",
    "# data_features[k][r] == np.array (ndim, t); K (number of letters) of R samples with Tr individual lengths\n",
    "print((data_features[1][1].shape))\n",
    "print(data_labels)\n",
    "\n",
    "# Works! But test on easier features\n",
    "\n",
    "### train for k = 1\n",
    "\n",
    "obs = data_features[1]\n",
    "\n",
    "# obsTA = np.array([ hm_learn.rand(100)[0] for _ in range(10) ])\n",
    "\n",
    "# print(type(obsTA))\n",
    "# print(obsTA[1].shape) == (100,2)\n",
    "# Our data has format (2,15) ! Transpose all datapoints\n",
    "for i in range(len(obs)):\n",
    "    obs[i] = np.transpose(obs[i])\n",
    "    \n",
    "print(len(obs))\n",
    "print(obs[len(obs)-1].shape)\n",
    "print(type(obs))\n",
    "\n",
    "print(obs[1])\n",
    "\n",
    "\n",
    "### training\n",
    "\n",
    "# Estimate the HMM parameters from the obseved samples\n",
    "# Start by. assigning initial HMM parameter values,\n",
    "# then refine these iteratively\n",
    "qstar = np.array([0.9, 0.1])\n",
    "Astar = np.array([[0.5, 0.5], [0.5, 0.5]])\n",
    "\n",
    "meansstar = np.array( [[0, 0], [0, 0]] )\n",
    "\n",
    "covsstar  = np.array( [[[1, 0],[0, 1]], \n",
    "                       [[1, 0],[0,1]]] )\n",
    "\n",
    "Bstar = np.array([multigaussD(meansstar[0], covsstar[0]),\n",
    "                  multigaussD(meansstar[1], covsstar[1])])\n",
    "\n",
    "\n",
    "hm_learn = HMM_TA.HMM(qstar, Astar, Bstar)\n",
    "\n",
    "print(\"Running the Baum Welch Algorithm...\")\n",
    "hm_learn.baum_welch(obs, 20, prin=1, uselog=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TA test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a HMM\n",
    "q = np.array([0.8, 0.2])\n",
    "A = np.array([[0.95, 0.05],\n",
    "            [0.30, 0.70]])\n",
    "\n",
    "means = np.array( [[0, 0], [2, 2]] )\n",
    "covs  = np.array( [[[1, 2],[2, 4]], \n",
    "                [[1, 0],[0, 3]]] )\n",
    "\n",
    "B = np.array([multigaussD(means[0], covs[0]),\n",
    "            multigaussD(means[1], covs[1])])\n",
    "\n",
    "\n",
    "hm  = HMM_TA.HMM(q, A, B)\n",
    "\n",
    "\n",
    "# Test that baum_welch works with inputs on the same format as us\n",
    "obs = []  \n",
    "for i in range(10): \n",
    "    obs += [hm.rand(100)[0]]\n",
    "\n",
    "print(obs[1].shape)\n",
    "print(obs[1])\n",
    "print(type(obs))\n",
    "\n",
    "print('True HMM parameters:')\n",
    "print('q:')\n",
    "print(q)\n",
    "print('A:')\n",
    "print(A)\n",
    "print('B: means, covariances')\n",
    "print(means)\n",
    "print(covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the HMM parameters from the obseved samples\n",
    "# Start by. assigning initial HMM parameter values,\n",
    "# then refine these iteratively\n",
    "qstar = np.array([0.8, 0.2])\n",
    "Astar = np.array([[0.5, 0.5], [0.5, 0.5]])\n",
    "\n",
    "meansstar = np.array( [[0, 0], [0, 0]] )\n",
    "\n",
    "covsstar  = np.array( [[[1, 0],[0, 1]], \n",
    "                       [[1, 0],[0,1]]] )\n",
    "\n",
    "Bstar = np.array([multigaussD(meansstar[0], covsstar[0]),\n",
    "                  multigaussD(meansstar[1], covsstar[1])])\n",
    "\n",
    "\n",
    "hm_learn = HMM_TA.HMM(qstar, Astar, Bstar)\n",
    "\n",
    "print(\"Running the Baum Welch Algorithm...\")\n",
    "hm_learn.baum_welch(obs, 20, prin=1, uselog=False)\n",
    "\n",
    "# obs is in the format:\n",
    "# obsTA = np.array([ hm.rand(100)[0] for _ in range(10) ])\n",
    "# ; shape (10 2 100)\n",
    "\n",
    "# test\n",
    "# Test the Viterbi algorithm\n",
    "print(\"Running the Viterbi Algorithm...\")\n",
    "obs, true_states = hm.rand(100)\n",
    "\n",
    "print(\"True States:\\n\",true_states)\n",
    "print(\"Predicted States:\\n\", hm_learn.viterbi(obs))\n",
    "\n",
    "####### SOMETIMES ALL RESULTS ARE TRANSPOSED/INVERTED MATRIXES!!!\n",
    "####### and sometimes it just works. Great stuff\n",
    "\n",
    "# descision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get symbol-1 (small p on top left quadrant)\n",
    "dc1 = np.load(\"data/P_top_left.npy\")\n",
    "\n",
    "#Get symbol-2 (small p on bottom right quadrant)\n",
    "dc2 = np.load(\"data/P_bottom_right.npy\")\n",
    "\n",
    "#Get symbol-3(twice as big p filling entire window)\n",
    "dc3 = np.load(\"data/P_big.npy\")\n",
    "\n",
    "thr = 8 # threshold for sampling and distance normalization\n",
    "\n",
    "# #Feature vectors are returned\n",
    "feature_symbol1, sampled_symbol1 = featureExtractor(dc1,thr,False)\n",
    "feature_symbol2, sampled_symbol2 = featureExtractor(dc2,thr,False)\n",
    "feature_symbol3, sampled_symbol3 = featureExtractor(dc3,thr,False)\n",
    "\n",
    "\n",
    "# normalized distance ,slope, and t for symbol-1\n",
    "f1_symbol1 = feature_symbol1[0]\n",
    "f2_symbol1 = feature_symbol1[1]\n",
    "t1 = np.array(range(0,feature_symbol1.shape[1]))\n",
    "\n",
    "\n",
    "# normalized distance ,slope, and t for symbol-2\n",
    "f1_symbol2 = feature_symbol2[0]\n",
    "f2_symbol2 = feature_symbol2[1]\n",
    "t2 = np.array(range(0,feature_symbol2.shape[1]))\n",
    "\n",
    "# normalized distance ,slope, and t for symbol-2\n",
    "f1_symbol3 = feature_symbol3[0]\n",
    "f2_symbol3 = feature_symbol3[1]\n",
    "t3 = np.array(range(0,feature_symbol3.shape[1]))\n",
    "\n",
    "f, axarr = plt.subplots(3, 3)\n",
    "f.suptitle('Scale & Position Effect', fontsize=20)\n",
    "\n",
    "\n",
    "#------------- SYMBOL DRAWINGS\n",
    "#Drawing of sampled symbol-1\n",
    "axarr[0, 0].scatter(sampled_symbol1[0], sampled_symbol1[1])\n",
    "axarr[0, 0].set(xlabel = \"X-Coordinate\", ylabel = \"Y-Coordinate\")\n",
    "axarr[0, 0].set_title('Symbol-1')\n",
    "axarr[0, 0].set_xlim([0,210])\n",
    "axarr[0, 0].set_ylim([0,210])\n",
    "\n",
    "#Drawing of sampled symbol-2\n",
    "axarr[0, 1].scatter(sampled_symbol2[0], sampled_symbol2[1])\n",
    "axarr[0, 1].set(xlabel = \"X-Coordinate\", ylabel = \"Y-Coordinate\")\n",
    "axarr[0, 1].set_title('Symbol-2')\n",
    "axarr[0, 1].set_xlim([0,210])\n",
    "axarr[0, 1].set_ylim([0,210])\n",
    "\n",
    "#Drawing of sampled symbol-3\n",
    "axarr[0, 2].scatter(sampled_symbol3[0], sampled_symbol3[1])\n",
    "axarr[0, 2].set(xlabel = \"X-Coordinate\", ylabel = \"Y-Coordinate\")\n",
    "axarr[0, 2].set_title('Symbol-3')\n",
    "axarr[0, 2].set_xlim([0,210])\n",
    "axarr[0, 2].set_ylim([0,210])\n",
    "\n",
    "#------------- ABSOLUTE DISTANCE FEATURE\n",
    "\n",
    "#Absolute distance plot of symbol-1\n",
    "axarr[1, 0].plot(t1, f1_symbol1)\n",
    "axarr[1, 0].set(xlabel = \"Time\", ylabel = \"Normalized Distance\")\n",
    "axarr[1, 0].set_ylim([0,np.max(f1_symbol1)])\n",
    "\n",
    "#Absolute distance plot of symbol-2\n",
    "axarr[1, 1].plot(t2, f1_symbol2)\n",
    "axarr[1, 1].set(xlabel = \"Time\", ylabel = \"Normalized Distance\")\n",
    "axarr[1, 1].set_ylim([0,np.max(f1_symbol2)])\n",
    "\n",
    "#Absolute distance plot of symbol-3\n",
    "axarr[1, 2].plot(t3, f1_symbol3)\n",
    "axarr[1, 2].set(xlabel = \"Time\", ylabel = \"Normalized Distance\")\n",
    "axarr[1, 2].set_ylim([0,np.max(f1_symbol3)])\n",
    "\n",
    "#------------- SLOPE FEATURE\n",
    "\n",
    "#Y-wise distance plot of symbol-1\n",
    "axarr[2, 0].plot(t1, f2_symbol1)\n",
    "axarr[2, 0].set(xlabel = \"Time\", ylabel = \"Slope(Degrees)\")\n",
    "axarr[2, 0].set_ylim([-120,120])\n",
    "\n",
    "#Y-wise distance plot of symbol-2\n",
    "axarr[2, 1].plot(t2, f2_symbol2)\n",
    "axarr[2, 1].set(xlabel = \"Time\", ylabel = \"Slope(Degrees)\")\n",
    "axarr[2, 1].set_ylim([-120,120])\n",
    "\n",
    "#Y-wise distance plot of symbol-3\n",
    "axarr[2, 2].plot(t3, f2_symbol3)\n",
    "axarr[2, 2].set(xlabel = \"Time\", ylabel = \"Slope(Degrees)\")\n",
    "axarr[2, 2].set_ylim([-120,120])\n",
    "\n",
    "plt.savefig('fig/P_test.png', bbox_inches='tight', dpi = 300)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
