{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we are going to improve our codes in PattRecClasses and implement forward algorithm inside MarkovChain code as well as functions such as logprob and prob in Guassian in order to generate proper input values for forward algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from CharacterFeatureExtractor import featureExtractor\n",
    "from DrawCharacter import DrawCharacter\n",
    "from PattRecClasses import HMM_TA \n",
    "from hmm_gen import hmm_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Multivariate Gaussian Distribution Class\n",
    "'''\n",
    "class multigaussD:\n",
    "    mean = np.array([0])\n",
    "    cov = np.array([[0]])\n",
    "    def __init__(self, mu, C):\n",
    "        if C.shape[0] is not C.shape[1]:\n",
    "            print(\"error, non-square covariance matrix supplied\")\n",
    "            return\n",
    "        if mu.shape[0] is not C.shape[0]:\n",
    "            print(\"error, mismatched mean vector and covariance matrix dimensions\")\n",
    "            return\n",
    "        self.mean = mu\n",
    "        if np.where(np.diag(C)==0)[0].shape[0] != 0:\n",
    "            C += np.diagflat(np.ones(C.shape[0])/10000)\n",
    "        C[np.isnan(C)]=1\n",
    "        self.cov = C\n",
    "        return\n",
    "    def random(self, num):\n",
    "        return np.random.multivariate_normal(self.mean, self.cov, num)\n",
    "    def rand(self):\n",
    "        return np.random.multivariate_normal(self.mean, self.cov, 1)[0]\n",
    "    def likelihood(self, X):\n",
    "        p = scipy.stats.multivariate_normal(self.mean, self.cov, 1)\n",
    "        pd = p.pdf(X)\n",
    "        return pd\n",
    "    def loghood(self, X):\n",
    "        return np.log(self.likelihood(X))\n",
    "    def getmean(self):\n",
    "        return self.mean\n",
    "    def getcov(self):\n",
    "        return self.cov\n",
    "    \n",
    "def prob(x, B):\n",
    "    T = x.shape[0]\n",
    "    N = B.shape[0]\n",
    "    res = np.zeros((T, N))\n",
    "    for i in range(T):\n",
    "        for j in range(N):\n",
    "            res[i,j] = B[j].likelihood(x[i])\n",
    "    scaled = np.zeros(res.shape)\n",
    "    for i in range(scaled.shape[0]):\n",
    "        for j in range(scaled.shape[1]):\n",
    "            scaled[i, j] = res[i,j]/np.amax(res[i])\n",
    "    return res, scaled\n",
    "\n",
    "\n",
    "def logprob(x, B):\n",
    "    res, scaled = prob(x,B)\n",
    "    return np.log(res), np.log(scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'C', 'K', 'P', 'X', 'T', '+', 'N', 'V', '4']\n",
      "[[[1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]]]\n",
      "[ 10 -60]\n"
     ]
    }
   ],
   "source": [
    "### data prep\n",
    "db_name = \"database_inc_sampchar\"\n",
    "data_features = pd.read_pickle(r'data/' + db_name + '_features.cdb')\n",
    "data_labels = pd.read_pickle(r'data/' + db_name + '_labels.cdb')\n",
    "\n",
    "# data_features[k][r] == np.array (ndim, t); K (number of letters) of R samples with Tr individual lengths\n",
    "# print((data_features[1][1].shape))\n",
    "print(data_labels)\n",
    "\n",
    "# train for one character (seen from labels)\n",
    "\n",
    "hm_learn = [0,0,0,0,0]\n",
    "\n",
    "# Start by assigning initial HMM parameter values,\n",
    "# then refine these iteratively\n",
    "\n",
    "# A (char = 0)\n",
    "# States = 3\n",
    "qstar = np.array([1, 0, 0])\n",
    "Astar = np.array([[0.9, 0.1, 0], [0, 0.9, 0.1], [0, 0, 1]])\n",
    "meansstar = np.array([[10, 60], [10, -70], [40,0]])\n",
    "covsstar = np.array([[[1, 1], [1, 1]],\n",
    "                     [[1, 1], [1, 1]], [[1,1],[1,1]]])\n",
    "\n",
    "print(covsstar)\n",
    "\n",
    "Bstar = np.array([multigaussD(meansstar[0], covsstar[0]),\n",
    "                  multigaussD(meansstar[1], covsstar[1]), \n",
    "                  multigaussD(meansstar[2], covsstar[2])])\n",
    "\n",
    "hm_learn[0] = HMM_TA.HMM(qstar, Astar, Bstar)\n",
    "\n",
    "# C (char = 1)\n",
    "# States = 5 ...\n",
    "\n",
    "# X (char = 4)\n",
    "# States = 2\n",
    "qstar = np.array([1, 0])\n",
    "Astar = np.array([[0.9, 0.1], [0, 1]])\n",
    "meansstar = np.array([[10, -60], [45, 70]])\n",
    "covsstar = np.array([[[1, 1], [1, 1]],\n",
    "                     [[1, 1], [1, 1]]])\n",
    "Bstar = np.array([multigaussD(meansstar[0], covsstar[0]),\n",
    "                  multigaussD(meansstar[1], covsstar[1])])\n",
    "\n",
    "print(meansstar[0])\n",
    "\n",
    "\n",
    "hm_learn[4] = HMM_TA.HMM(qstar, Astar, Bstar)\n",
    "\n",
    "hm_learn[1] = hm_learn[0]\n",
    "hm_learn[2] = hm_learn[0]\n",
    "hm_learn[3] = hm_learn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ CHARACTER 0 ------------\n",
      "Number of states 4\n",
      "qstar [0.25 0.25 0.25 0.25]\n",
      "Astar [[0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]]\n",
      "Bstar mean: [[  7.8131289   50.20323097]\n",
      " [  9.19508602  -5.7886445 ]\n",
      " [ 40.06771142 -32.72642421]\n",
      " [ 41.90543376 -16.35881107]] covariance: [[[1.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 1.00000000e+00]]\n",
      "\n",
      " [[2.42000094e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 4.35482185e+03]]\n",
      "\n",
      " [[1.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 1.00000000e+00]]\n",
      "\n",
      " [[3.37722340e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 2.67898760e+02]]]\n",
      "\n",
      "\n",
      "------------ CHARACTER 1 ------------\n",
      "Number of states 6\n",
      "qstar [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      "Astar [[0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      " [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      " [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      " [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      " [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      " [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]]\n",
      "Bstar mean: [[  9.69412345  -2.11142571]\n",
      " [  9.4429762   32.00735475]\n",
      " [  9.37925183  30.00197154]\n",
      " [  7.81924474 -50.19245737]\n",
      " [  9.85785287 -23.96051744]\n",
      " [  9.56162545  -6.0234209 ]] covariance: [[[1.98288275e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 8.93289586e+00]]\n",
      "\n",
      " [[1.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 1.00000000e+00]]\n",
      "\n",
      " [[1.98288275e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 6.46597568e+03]]\n",
      "\n",
      " [[1.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 1.00000000e+00]]\n",
      "\n",
      " [[1.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 1.00000000e+00]]\n",
      "\n",
      " [[2.47252830e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 9.90986019e-02]]]\n",
      "\n",
      "\n",
      "------------ CHARACTER 2 ------------\n",
      "Number of states 4\n",
      "qstar [0.25 0.25 0.25 0.25]\n",
      "Astar [[0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]]\n",
      "Bstar mean: [[  9.74250701  34.1810547 ]\n",
      " [  9.53035142   3.17488134]\n",
      " [ 37.10964898  24.34159195]\n",
      " [ 37.43766401 -35.57966156]] covariance: [[[1.35357968e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 6.23257783e+03]]\n",
      "\n",
      " [[2.23074309e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 7.53943225e+03]]\n",
      "\n",
      " [[2.84811932e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 2.20181106e+03]]\n",
      "\n",
      " [[3.57996016e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 4.88794902e+02]]]\n",
      "\n",
      "\n",
      "------------ CHARACTER 3 ------------\n",
      "Number of states 3\n",
      "qstar [0.33333333 0.33333333 0.33333333]\n",
      "Astar [[0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]]\n",
      "Bstar mean: [[  9.45191231  80.19644551]\n",
      " [ 47.04818512 -22.50337794]\n",
      " [ 46.46327232  -4.72562708]] covariance: [[[4.04335526e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 2.21896873e+01]]\n",
      "\n",
      " [[7.43466596e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 2.80667252e+03]]\n",
      "\n",
      " [[4.82944178e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 2.31937329e+03]]]\n",
      "\n",
      "\n",
      "------------ CHARACTER 4 ------------\n",
      "Number of states 2\n",
      "qstar [0.5 0.5]\n",
      "Astar [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "Bstar mean: [[  9.70879318 -51.73834002]\n",
      " [ 39.28542723  40.57723261]] covariance: [[[6.31364072e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 2.76561261e+01]]\n",
      "\n",
      " [[1.40168136e+02 0.00000000e+00]\n",
      "  [0.00000000e+00 1.57338299e+03]]]\n",
      "\n",
      "\n",
      "------------ CHARACTER 5 ------------\n",
      "Number of states 5\n",
      "qstar [0.2 0.2 0.2 0.2 0.2]\n",
      "Astar [[0.2 0.2 0.2 0.2 0.2]\n",
      " [0.2 0.2 0.2 0.2 0.2]\n",
      " [0.2 0.2 0.2 0.2 0.2]\n",
      " [0.2 0.2 0.2 0.2 0.2]\n",
      " [0.2 0.2 0.2 0.2 0.2]]\n",
      "Bstar mean: [[ 1.12541807e+01  6.18624811e-03]\n",
      " [ 1.06517231e+01  1.29429206e+00]\n",
      " [ 2.14743418e+01  1.85379651e+00]\n",
      " [ 2.18959769e+01 -2.40860682e+01]\n",
      " [ 2.22834140e+01  5.50450720e+01]] covariance: [[[1.18760000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 1.00000000e-04]]\n",
      "\n",
      " [[2.54839010e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 1.16145160e+01]]\n",
      "\n",
      " [[1.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 1.00000000e+00]]\n",
      "\n",
      " [[7.22853964e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 6.51748678e+03]]\n",
      "\n",
      " [[1.63958101e-01 0.00000000e+00]\n",
      "  [0.00000000e+00 4.88911803e+03]]]\n",
      "\n",
      "\n",
      "------------ CHARACTER 6 ------------\n",
      "Number of states 3\n",
      "qstar [0.33333333 0.33333333 0.33333333]\n",
      "Astar [[0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]]\n",
      "Bstar mean: [[ 10.92668949   2.59665876]\n",
      " [ 28.25489275 -39.80544417]\n",
      " [ 29.83423348  70.55073224]] covariance: [[[1.86886984e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 2.04392867e+01]]\n",
      "\n",
      " [[1.00000000e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 1.00000000e+00]]\n",
      "\n",
      " [[3.34743959e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 2.03453309e+03]]]\n",
      "\n",
      "\n",
      "------------ CHARACTER 7 ------------\n",
      "Number of states 3\n",
      "qstar [0.33333333 0.33333333 0.33333333]\n",
      "Astar [[0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]]\n",
      "Bstar mean: [[ 8.4982735   2.36572205]\n",
      " [ 7.54502402 82.4550305 ]\n",
      " [ 5.56671539 86.76032777]] covariance: [[[2.10280031e+01 0.00000000e+00]\n",
      "  [0.00000000e+00 5.66949042e+03]]\n",
      "\n",
      " [[6.02537368e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 2.04855227e+01]]\n",
      "\n",
      " [[1.52813574e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 3.16612623e+01]]]\n",
      "\n",
      "\n",
      "------------ CHARACTER 8 ------------\n",
      "Number of states 4\n",
      "qstar [0.25 0.25 0.25 0.25]\n",
      "Astar [[0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]]\n",
      "Bstar mean: [[  9.66313041 -69.43540893]\n",
      " [  4.24633508  45.00248119]\n",
      " [  9.45773668  59.87212116]\n",
      " [ 10.49846917  61.47142333]] covariance: [[[ 1.61196252  0.        ]\n",
      "  [ 0.         22.23734626]]\n",
      "\n",
      " [[ 1.          0.        ]\n",
      "  [ 0.          1.        ]]\n",
      "\n",
      " [[ 0.49608453  0.        ]\n",
      "  [ 0.         30.94887779]]\n",
      "\n",
      " [[ 0.05970247  0.        ]\n",
      "  [ 0.         14.54516999]]]\n",
      "\n",
      "\n",
      "------------ CHARACTER 9 ------------\n",
      "Number of states 3\n",
      "qstar [0.33333333 0.33333333 0.33333333]\n",
      "Astar [[0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]]\n",
      "Bstar mean: [[ 9.86713659 59.63494393]\n",
      " [11.37629866 -4.51511475]\n",
      " [18.40179993 68.67441185]] covariance: [[[1.54828872e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 6.50743915e+02]]\n",
      "\n",
      " [[4.52208425e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 1.91560177e+02]]\n",
      "\n",
      " [[9.80555556e+00 0.00000000e+00]\n",
      "  [0.00000000e+00 2.27551049e+03]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------ CHARACTER A ------------\n",
      "Training data 15\n",
      "Testing data 5\n",
      "Running the Baum Welch Algorithm...\n",
      "Estimated a:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'HMM' object has no attribute 'pi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5a8170d09ff6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running the Baum Welch Algorithm...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mhm_learn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaum_welch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muselog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Local/Pattern-Recognition-Project/PattRecClasses/HMM_TA.py\u001b[0m in \u001b[0;36mbaum_welch\u001b[0;34m(self, obs, niter, uselog, prin, scaled)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintoutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Local/Pattern-Recognition-Project/PattRecClasses/HMM_TA.py\u001b[0m in \u001b[0;36mprintoutput\u001b[0;34m(self, newmean, newcov)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprintoutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Estimated a:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Estimated A:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HMM' object has no attribute 'pi'"
     ]
    }
   ],
   "source": [
    "hm_learn = hmm_gen(data_features, 10)\n",
    "train_data = []\n",
    "test_data = []\n",
    "train_results = []\n",
    "\n",
    "for char in range(3):  # len(data_features)\n",
    "    print(\"\\n\")\n",
    "    print(\"------------ CHARACTER\", data_labels[char], \"------------\")\n",
    "    # Data preprocessing \n",
    "    obs = data_features[char]\n",
    "    # oos_obs = data_features[char-1]\n",
    "    \n",
    "    # obsTA = np.array([ hm_learn.rand(100)[0] for _ in range(10) ])\n",
    "    # print(type(obsTA))\n",
    "    # print(obsTA[1].shape) == (100,2)\n",
    "    # Our data has format (2,15) ! Transpose all datapoints\n",
    "    for i in range(len(obs)):\n",
    "        obs[i] = np.transpose(obs[i])\n",
    "    \n",
    "    #data_features[char] = obs  # so we do not have to reinvert the data later\n",
    "    \n",
    "    #for i in range(len(oos_obs)):\n",
    "    #    oos_obs[i] = np.transpose(oos_obs[i])\n",
    "\n",
    "    # Data information\n",
    "    \"\"\"\n",
    "    print(len(obs))\n",
    "    print(obs[len(obs) - 1].shape)\n",
    "    print(type(obs))\n",
    "    print(obs[1])\n",
    "    \"\"\"\n",
    "\n",
    "    # Divide data into training and testing\n",
    "    \n",
    "    train_obs = obs[0:len(obs)-5]\n",
    "    test_obs = obs[len(obs)-5:len(obs)]\n",
    "    \n",
    "    print(\"Training data\", len(train_obs))\n",
    "    print(\"Testing data\", len(test_obs))\n",
    "    \n",
    "    # Training\n",
    "    print(\"Running the Baum Welch Algorithm...\")\n",
    "    hm_learn[char].baum_welch(train_obs, 20, prin=1, uselog=False)\n",
    "\n",
    "    \n",
    "    # Testing on out of sample and test obs\n",
    "    \n",
    "    #a, c = hm_learn[char].alphahat(oos_obs[2])\n",
    "    #print(\"Prob oos\", c)\n",
    "    lprob_list = []\n",
    "    for test in test_obs:\n",
    "        a, c = hm_learn[char].alphahat(test)\n",
    "        print(\"c is\", c)\n",
    "        clog = np.log(c)\n",
    "        lprob = np.sum(np.array(clog))\n",
    "        lprob_list += [lprob]\n",
    "    avg = np.mean(np.array(lprob_list))\n",
    "    print(\"Avg probability over test samples is\", np.exp(avg))\n",
    "    train_results += [avg]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
