{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we are going to improve our codes in PattRecClasses and implement forward algorithm inside MarkovChain code as well as functions such as logprob and prob in Guassian in order to generate proper input values for forward algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from CharacterFeatureExtractor import featureExtractor\n",
    "from DrawCharacter import DrawCharacter\n",
    "from PattRecClasses import HMM_TA \n",
    "from hmm_gen import hmm_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Multivariate Gaussian Distribution Class\n",
    "'''\n",
    "class multigaussD:\n",
    "    mean = np.array([0])\n",
    "    cov = np.array([[0]])\n",
    "    def __init__(self, mu, C):\n",
    "        if C.shape[0] is not C.shape[1]:\n",
    "            print(\"error, non-square covariance matrix supplied\")\n",
    "            return\n",
    "        if mu.shape[0] is not C.shape[0]:\n",
    "            print(\"error, mismatched mean vector and covariance matrix dimensions\")\n",
    "            return\n",
    "        self.mean = mu\n",
    "        if np.where(np.diag(C)==0)[0].shape[0] != 0:\n",
    "            C += np.diagflat(np.ones(C.shape[0])/10000)\n",
    "        C[np.isnan(C)]=1\n",
    "        self.cov = C\n",
    "        return\n",
    "    def random(self, num):\n",
    "        return np.random.multivariate_normal(self.mean, self.cov, num)\n",
    "    def rand(self):\n",
    "        return np.random.multivariate_normal(self.mean, self.cov, 1)[0]\n",
    "    def likelihood(self, X):\n",
    "        p = scipy.stats.multivariate_normal(self.mean, self.cov, 1)\n",
    "        pd = p.pdf(X)\n",
    "        return pd\n",
    "    def loghood(self, X):\n",
    "        return np.log(self.likelihood(X))\n",
    "    def getmean(self):\n",
    "        return self.mean\n",
    "    def getcov(self):\n",
    "        return self.cov\n",
    "    \n",
    "def prob(x, B):\n",
    "    T = x.shape[0]\n",
    "    N = B.shape[0]\n",
    "    res = np.zeros((T, N))\n",
    "    for i in range(T):\n",
    "        for j in range(N):\n",
    "            res[i,j] = B[j].likelihood(x[i])\n",
    "    scaled = np.zeros(res.shape)\n",
    "    for i in range(scaled.shape[0]):\n",
    "        for j in range(scaled.shape[1]):\n",
    "            scaled[i, j] = res[i,j]/np.amax(res[i])\n",
    "    return res, scaled\n",
    "\n",
    "\n",
    "def logprob(x, B):\n",
    "    res, scaled = prob(x,B)\n",
    "    return np.log(res), np.log(scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'C', 'K', 'P', 'X']\n",
      "[[[1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [1 1]]]\n",
      "[ 10 -60]\n"
     ]
    }
   ],
   "source": [
    "### data prep\n",
    "db_name = \"database_test\"\n",
    "data_features = pd.read_pickle(r'data/' + db_name + '_features.cdb')\n",
    "data_labels = pd.read_pickle(r'data/' + db_name + '_labels.cdb')\n",
    "\n",
    "# data_features[k][r] == np.array (ndim, t); K (number of letters) of R samples with Tr individual lengths\n",
    "# print((data_features[1][1].shape))\n",
    "print(data_labels)\n",
    "\n",
    "# train for one character (seen from labels)\n",
    "\n",
    "hm_learn = [0,0,0,0,0]\n",
    "\n",
    "# Start by assigning initial HMM parameter values,\n",
    "# then refine these iteratively\n",
    "\n",
    "# A (char = 0)\n",
    "# States = 3\n",
    "qstar = np.array([1, 0, 0])\n",
    "Astar = np.array([[0.9, 0.1, 0], [0, 0.9, 0.1], [0, 0, 1]])\n",
    "meansstar = np.array([[10, 60], [10, -70], [40,0]])\n",
    "covsstar = np.array([[[1, 1], [1, 1]],\n",
    "                     [[1, 1], [1, 1]], [[1,1],[1,1]]])\n",
    "\n",
    "print(covsstar)\n",
    "\n",
    "Bstar = np.array([multigaussD(meansstar[0], covsstar[0]),\n",
    "                  multigaussD(meansstar[1], covsstar[1]), \n",
    "                  multigaussD(meansstar[2], covsstar[2])])\n",
    "\n",
    "hm_learn[0] = HMM_TA.HMM(qstar, Astar, Bstar)\n",
    "\n",
    "# C (char = 1)\n",
    "# States = 5 ...\n",
    "\n",
    "# X (char = 4)\n",
    "# States = 2\n",
    "qstar = np.array([1, 0])\n",
    "Astar = np.array([[0.9, 0.1], [0, 1]])\n",
    "meansstar = np.array([[10, -60], [45, 70]])\n",
    "covsstar = np.array([[[1, 1], [1, 1]],\n",
    "                     [[1, 1], [1, 1]]])\n",
    "Bstar = np.array([multigaussD(meansstar[0], covsstar[0]),\n",
    "                  multigaussD(meansstar[1], covsstar[1])])\n",
    "\n",
    "print(meansstar[0])\n",
    "\n",
    "\n",
    "hm_learn[4] = HMM_TA.HMM(qstar, Astar, Bstar)\n",
    "\n",
    "hm_learn[1] = hm_learn[0]\n",
    "hm_learn[2] = hm_learn[0]\n",
    "hm_learn[3] = hm_learn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ CHARACTER 0 ------------\n",
      "Number of states 4\n",
      "qstar [1. 0. 0. 0.]\n",
      "Astar [[0.9 0.1 0.  0. ]\n",
      " [0.  0.9 0.1 0. ]\n",
      " [0.  0.  0.9 0.1]\n",
      " [0.  0.  0.  1. ]]\n",
      "Bstar [[  7.81078884  50.19884682]\n",
      " [  9.19274596  -5.79302865]\n",
      " [ 40.06537137 -32.73080836]\n",
      " [ 41.90309371 -16.36319523]]\n",
      "\n",
      "\n",
      "------------ CHARACTER 1 ------------\n",
      "Number of states 6\n",
      "qstar [1. 0. 0. 0. 0. 0.]\n",
      "Astar [[0.9 0.1 0.  0.  0.  0. ]\n",
      " [0.  0.9 0.1 0.  0.  0. ]\n",
      " [0.  0.  0.9 0.1 0.  0. ]\n",
      " [0.  0.  0.  0.9 0.1 0. ]\n",
      " [0.  0.  0.  0.  0.9 0.1]\n",
      " [0.  0.  0.  0.  0.  1. ]]\n",
      "Bstar [[  9.69096999  -2.11022837]\n",
      " [  9.43982274  32.00855209]\n",
      " [  9.37609837  30.00316888]\n",
      " [  7.81609129 -50.19126002]\n",
      " [  9.85469941 -23.95932009]\n",
      " [  9.55847199  -6.02222356]]\n",
      "\n",
      "\n",
      "------------ CHARACTER 2 ------------\n",
      "Number of states 4\n",
      "qstar [1. 0. 0. 0.]\n",
      "Astar [[0.9 0.1 0.  0. ]\n",
      " [0.  0.9 0.1 0. ]\n",
      " [0.  0.  0.9 0.1]\n",
      " [0.  0.  0.  1. ]]\n",
      "Bstar [[  9.74360566  34.18011984]\n",
      " [  9.53145007   3.17394648]\n",
      " [ 37.11074763  24.34065709]\n",
      " [ 37.43876266 -35.58059642]]\n",
      "\n",
      "\n",
      "------------ CHARACTER 3 ------------\n",
      "Number of states 3\n",
      "qstar [1. 0. 0.]\n",
      "Astar [[0.9 0.1 0. ]\n",
      " [0.  0.9 0.1]\n",
      " [0.  0.  1. ]]\n",
      "Bstar [[  9.45798431  80.19601789]\n",
      " [ 47.05425712 -22.50380556]\n",
      " [ 46.46934432  -4.7260547 ]]\n",
      "\n",
      "\n",
      "------------ CHARACTER 4 ------------\n",
      "Number of states 2\n",
      "qstar [1. 0.]\n",
      "Astar [[0.9 0.1]\n",
      " [0.  1. ]]\n",
      "Bstar [[  9.70440625 -51.73858663]\n",
      " [ 39.2810403   40.576986  ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------ CHARACTER A ------------\n",
      "Running the Baum Welch Algorithm...\n",
      "Estimated a:\n",
      "[1. 0. 0. 0.]\n",
      "\n",
      "Estimated A:\n",
      "[[0.89655241 0.10344759 0.         0.        ]\n",
      " [0.         0.88888809 0.11111191 0.        ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         0.         1.        ]]\n",
      "\n",
      "Estimated means:\n",
      "[[  9.32031917  55.80638679]\n",
      " [  9.06013146 -64.33851859]\n",
      " [ 37.31641762 -34.10218927]\n",
      " [ 38.49353808  -2.18698433]]\n",
      "\n",
      "Estimated covariances:\n",
      "[[[  1.10202481   4.51931839]\n",
      "  [  4.51931839 204.79674314]]\n",
      "\n",
      " [[  1.28541378  -3.57145182]\n",
      "  [ -3.57145182  84.43786417]]\n",
      "\n",
      " [[  3.77914318   1.98100887]\n",
      "  [  1.98100887  12.93121985]]\n",
      "\n",
      " [[  6.7437034    2.45794698]\n",
      "  [  2.45794698   8.42615984]]]\n",
      "Prob is [1.         0.89655241 0.89655241 0.89655241 0.89655241 0.89655241\n",
      " 0.10344759 0.88888809 0.88888809 0.88888809 0.88888809 0.88888809\n",
      " 0.88888809 0.11111191 1.         1.        ]\n",
      "\n",
      "\n",
      "------------ CHARACTER C ------------\n",
      "Running the Baum Welch Algorithm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/Local/Pattern-Recognition-Project/PattRecClasses/HMM_TA.py:96: RuntimeWarning: overflow encountered in true_divide\n",
      "  beta[t] = temp / cs[t]\n",
      "/home/jonas/Local/Pattern-Recognition-Project/PattRecClasses/HMM_TA.py:95: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  temp[i] += A[i, j] * scaled[t + 1, j] * beta[t + 1, j]\n",
      "/home/jonas/Local/Pattern-Recognition-Project/PattRecClasses/HMM_TA.py:145: RuntimeWarning: invalid value encountered in multiply\n",
      "  temp += [alphahats[i][t] * betahats[i][t] * cs[i][t]]\n",
      "/home/jonas/Local/Pattern-Recognition-Project/PattRecClasses/HMM_TA.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  xi[t, j, k] = alphahats[i][t][j] * self.A[j, k] * scaled[t + 1][k] * betahats[i][t + 1][k]\n",
      "/home/jonas/Local/Pattern-Recognition-Project/PattRecClasses/HMM_TA.py:323: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  scaled[i, j] = res[i, j] / np.amax(res[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated a:\n",
      "[nan nan nan nan nan nan]\n",
      "\n",
      "Estimated A:\n",
      "[[nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan]]\n",
      "\n",
      "Estimated means:\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "\n",
      "Estimated covariances:\n",
      "[[[0.0001 0.    ]\n",
      "  [0.     0.0001]]\n",
      "\n",
      " [[0.0001 0.    ]\n",
      "  [0.     0.0001]]\n",
      "\n",
      " [[0.0001 0.    ]\n",
      "  [0.     0.0001]]\n",
      "\n",
      " [[0.0001 0.    ]\n",
      "  [0.     0.0001]]\n",
      "\n",
      " [[0.0001 0.    ]\n",
      "  [0.     0.0001]]\n",
      "\n",
      " [[0.0001 0.    ]\n",
      "  [0.     0.0001]]]\n",
      "Prob is [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan]\n",
      "\n",
      "\n",
      "------------ CHARACTER K ------------\n",
      "Running the Baum Welch Algorithm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/Local/Pattern-Recognition-Project/PattRecClasses/HMM_TA.py:61: RuntimeWarning: invalid value encountered in true_divide\n",
      "  alpha[t, :] = temp / c[t]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated a:\n",
      "[nan nan nan nan]\n",
      "\n",
      "Estimated A:\n",
      "[[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n",
      "\n",
      "Estimated means:\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "\n",
      "Estimated covariances:\n",
      "[[[0.0001 0.    ]\n",
      "  [0.     0.0001]]\n",
      "\n",
      " [[0.0001 0.    ]\n",
      "  [0.     0.0001]]\n",
      "\n",
      " [[0.0001 0.    ]\n",
      "  [0.     0.0001]]\n",
      "\n",
      " [[0.0001 0.    ]\n",
      "  [0.     0.0001]]]\n",
      "Prob is [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan]\n",
      "\n",
      "\n",
      "------------ CHARACTER P ------------\n",
      "Running the Baum Welch Algorithm...\n",
      "Estimated a:\n",
      "[nan nan nan]\n",
      "\n",
      "Estimated A:\n",
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "\n",
      "Estimated means:\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "\n",
      "Estimated covariances:\n",
      "[[[0.0001 0.    ]\n",
      "  [0.     0.0001]]\n",
      "\n",
      " [[0.0001 0.    ]\n",
      "  [0.     0.0001]]\n",
      "\n",
      " [[0.0001 0.    ]\n",
      "  [0.     0.0001]]]\n",
      "Prob is [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan]\n",
      "\n",
      "\n",
      "------------ CHARACTER X ------------\n",
      "Running the Baum Welch Algorithm...\n",
      "Estimated a:\n",
      "[1. 0.]\n",
      "\n",
      "Estimated A:\n",
      "[[0.9 0.1]\n",
      " [0.  1. ]]\n",
      "\n",
      "Estimated means:\n",
      "[[ 10.21573854 -57.85796827]\n",
      " [ 40.13213709  53.23985508]]\n",
      "\n",
      "Estimated covariances:\n",
      "[[[  1.34057437  -0.92564934]\n",
      "  [ -0.92564934  66.96510381]]\n",
      "\n",
      " [[ 39.81819851 -27.9325089 ]\n",
      "  [-27.9325089  123.2848896 ]]]\n",
      "Prob is [1.  0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.1 1.  1.  1.  1.  1.\n",
      " 1.  1.  1.  1.  1. ]\n"
     ]
    }
   ],
   "source": [
    "hm_learn = hmm_gen(data_features, 10)\n",
    "\n",
    "for char in range(len(data_features)):\n",
    "    print(\"\\n\")\n",
    "    print(\"------------ CHARACTER\", data_labels[char], \"------------\")\n",
    "    # Data preprocessing \n",
    "    obs = data_features[char]\n",
    "    # oos_obs = data_features[char-1]\n",
    "    \n",
    "    # obsTA = np.array([ hm_learn.rand(100)[0] for _ in range(10) ])\n",
    "    # print(type(obsTA))\n",
    "    # print(obsTA[1].shape) == (100,2)\n",
    "    # Our data has format (2,15) ! Transpose all datapoints\n",
    "    for i in range(len(obs)):\n",
    "        obs[i] = np.transpose(obs[i])\n",
    "    \n",
    "    #for i in range(len(oos_obs)):\n",
    "    #    oos_obs[i] = np.transpose(oos_obs[i])\n",
    "\n",
    "    # Data information\n",
    "    \"\"\"\n",
    "    print(len(obs))\n",
    "    print(obs[len(obs) - 1].shape)\n",
    "    print(type(obs))\n",
    "    print(obs[1])\n",
    "    \"\"\"\n",
    "\n",
    "    # Divide data into training and testing\n",
    "    train_obs = obs[0:3]\n",
    "    test_obs = obs[4]\n",
    "\n",
    "    # Training\n",
    "    print(\"Running the Baum Welch Algorithm...\")\n",
    "    hm_learn[char].baum_welch(train_obs, 20, prin=1, uselog=False)\n",
    "\n",
    "    \n",
    "    # Testing on out of sample and test obs\n",
    "    \n",
    "    #a, c = hm_learn[char].alphahat(oos_obs[2])\n",
    "    #print(\"Prob oos\", c)\n",
    "    \n",
    "    a, c = hm_learn[char].alphahat(test_obs)\n",
    "    print(\"Prob is\", c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
