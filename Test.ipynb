{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dataprep import dataprep\n",
    "from modeltrain import modeltrain\n",
    "from hmm_test import hmm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in master_list data from saved run and choose HMM models correspondingly\n",
    "\n",
    "# master_list = [cv_train_acc] + [cv_acc] + [hmm_list] + [train_list] + [test_list]\n",
    "\n",
    "filename = 'master_list50'\n",
    "\n",
    "master_list = pd.read_pickle(r'master_list50')\n",
    "\n",
    "# Choose metric to extract the best HMM model based on\n",
    "metric = master_list[0]\n",
    " \n",
    "\n",
    "best = np.zeros([2,10]) - 50  # make sure that it finds the extreme values\n",
    "itr = len(metric)\n",
    "for i in range(itr):\n",
    "    for k in range(10):\n",
    "        if metric[i][k] > best[0,k]:\n",
    "            best[0,k] = metric[i][k]  # best value\n",
    "            best[1,k] = i  # index of currently best model\n",
    "\n",
    "# Choose the hmm models corresponding to the metric\n",
    "hmm_list = master_list[2]\n",
    "hmm_best = []\n",
    "\n",
    "for k in range(10):\n",
    "    hmm_best += [hmm_list[int(best[1,2])][k]]\n",
    "    \n",
    "train_acc = best[0,:]\n",
    "# In this case we are using training accuracy, so save out the chosen parameters s.t. they can be plotted with the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.02032571 -8.83562523 -5.39754642 -4.49541909 -3.30549836 -2.98376423\n",
      "  -3.20041036 -7.04788349 -3.11322116 -3.96053459]\n",
      " [12.         29.         39.         34.         36.         13.\n",
      "   9.         13.          9.         12.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(best)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Database read is  database_inc_sampchar\n",
      "Labels used are  ['A', 'C', 'K', 'P', 'X', 'T', '+', 'N', 'V', '4']\n",
      "Total training samples are  5  and testing samples are  15 \n",
      "\n",
      "************* CLASSIFICATION RESULTS ************* \n",
      "Classification accuracy of test samples of character A is: 0.0%\n",
      "Classification accuracy of test samples of character C is: 0.0%\n",
      "Classification accuracy of test samples of character K is: 73.33333333333333%\n",
      "Classification accuracy of test samples of character P is: 40.0%\n",
      "Classification accuracy of test samples of character X is: 0.0%\n",
      "Classification accuracy of test samples of character T is: 60.0%\n",
      "Classification accuracy of test samples of character + is: 66.66666666666666%\n",
      "Classification accuracy of test samples of character N is: 0.0%\n",
      "Classification accuracy of test samples of character V is: 100.0%\n",
      "Classification accuracy of test samples of character 4 is: 20.0%\n"
     ]
    }
   ],
   "source": [
    "# Load training and testing data:\n",
    "useprint = True\n",
    "train_data, test_data, labels = dataprep(\"database_inc_sampchar\", useprint=useprint, shuffle=True, max_labels=0, max_samples=0, nr_test=15)\n",
    "\n",
    "# Evaluate trained model:\n",
    "acc, res_labl_list = hmm_test(hmm_best, test_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- RESULTS: ---------------- \n",
      "\n",
      " Character:  A\n",
      "Number of states:  3\n",
      "Test accuracy:  0.0 and resulting labels:  ['K', 'K', 'K', '4', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K']\n",
      "Training accuracy: (log) -4.0203257125453\n",
      "\n",
      " Character:  C\n",
      "Number of states:  3\n",
      "Test accuracy:  0.0 and resulting labels:  ['K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K']\n",
      "Training accuracy: (log) -8.835625232092639\n",
      "\n",
      " Character:  K\n",
      "Number of states:  3\n",
      "Test accuracy:  0.7333333333333333 and resulting labels:  ['K', 'K', 'P', 'K', 'K', 'K', 'K', 'K', 'V', 'K', 'K', 'P', 'K', 'K', 'P']\n",
      "Training accuracy: (log) -5.397546417128217\n",
      "\n",
      " Character:  P\n",
      "Number of states:  4\n",
      "Test accuracy:  0.4 and resulting labels:  ['K', 'K', 'K', 'P', 'K', 'P', 'K', 'P', 'P', 'K', 'K', 'P', 'K', 'K', 'P']\n",
      "Training accuracy: (log) -4.4954190897610244\n",
      "\n",
      " Character:  X\n",
      "Number of states:  4\n",
      "Test accuracy:  0.0 and resulting labels:  ['V', 'V', 'V', 'V', 'T', '+', 'V', 'V', 'V', 'V', 'V', 'V', 'T', 'V', 'V']\n",
      "Training accuracy: (log) -3.3054983596769367\n",
      "\n",
      " Character:  T\n",
      "Number of states:  2\n",
      "Test accuracy:  0.6 and resulting labels:  ['+', '+', '+', 'T', 'T', 'T', 'T', 'T', '+', '+', '+', 'T', 'T', 'T', 'T']\n",
      "Training accuracy: (log) -2.983764230703702\n",
      "\n",
      " Character:  +\n",
      "Number of states:  2\n",
      "Test accuracy:  0.6666666666666666 and resulting labels:  ['T', 'T', '+', '+', '+', '+', '+', '+', 'T', '+', 'T', 'T', '+', '+', '+']\n",
      "Training accuracy: (log) -3.200410355249684\n",
      "\n",
      " Character:  N\n",
      "Number of states:  4\n",
      "Test accuracy:  0.0 and resulting labels:  ['K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K']\n",
      "Training accuracy: (log) -7.047883486687825\n",
      "\n",
      " Character:  V\n",
      "Number of states:  2\n",
      "Test accuracy:  1.0 and resulting labels:  ['V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V']\n",
      "Training accuracy: (log) -3.1132211553490077\n",
      "\n",
      " Character:  4\n",
      "Number of states:  3\n",
      "Test accuracy:  0.2 and resulting labels:  ['K', 'K', '4', 'K', 'K', 'K', 'K', 'K', 'K', 'K', '4', 'K', 'K', 'K', '4']\n",
      "Training accuracy: (log) -3.9605345916976873\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------- RESULTS: ---------------- \")\n",
    "for k in range(len(labels)):\n",
    "    print(\"\\n Character: \", labels[k])\n",
    "    print(\"Number of states: \", len(hmm_best[k].q))\n",
    "    print(\"Test accuracy: \",acc[k], \"and resulting labels: \",res_labl_list[k])\n",
    "    print(\"Training accuracy: (log)\", train_acc[k])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
