{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dataprep import dataprep\n",
    "from modeltrain import modeltrain\n",
    "from hmm_test import hmm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in master_list data from saved run and choose HMM models correspondingly\n",
    "\n",
    "# master_list = [cv_train_acc] + [cv_acc] + [hmm_list] + [train_list] + [test_list]\n",
    "\n",
    "filename = 'master_list20'\n",
    "\n",
    "master_list = pd.read_pickle(r'master_list20')\n",
    "\n",
    "# Choose metric to extract the best HMM model based on\n",
    "cv_train_acc = master_list[0]\n",
    "metric = cv_train_acc\n",
    "\n",
    "best = np.zeros([2,10]) - 50  # make sure that it finds the extreme values\n",
    "itr = len(metric)\n",
    "for i in range(itr):\n",
    "    for k in range(10):\n",
    "        if metric[i][k] > best[0,k]:\n",
    "            best[0,k] = metric[i][k]  # best value\n",
    "            best[1,k] = i  # index of currently best model\n",
    "\n",
    "# Choose the hmm models corresponding to the metric\n",
    "hmm_list = master_list[2]\n",
    "hmm_best = []\n",
    "\n",
    "for k in range(10):\n",
    "    hmm_best += [hmm_list[int(best[1,2])][k]]\n",
    "    \n",
    "train_acc = best[0,:]\n",
    "# In this case we are using training accuracy, so save out the chosen parameters s.t. they can be plotted with the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.0523346  -9.29267595 -5.4944826  -5.24283359 -3.35732994 -2.94300993\n",
      "  -3.24378088 -6.96125914 -3.12352091 -4.53874903]\n",
      " [ 1.         10.          7.          5.         18.         13.\n",
      "   6.         10.         15.         15.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(best)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Database read is  database_inc_sampchar\n",
      "Labels used are  ['A', 'C', 'K', 'P', 'X', 'T', '+', 'N', 'V', '4']\n",
      "Total training samples are  5  and testing samples are  15 \n",
      "\n",
      "************* CLASSIFICATION RESULTS ************* \n",
      "Classification accuracy of test samples of character A is: 100.0%\n",
      "Classification accuracy of test samples of character C is: 0.0%\n",
      "Classification accuracy of test samples of character K is: 33.33333333333333%\n",
      "Classification accuracy of test samples of character P is: 6.666666666666667%\n",
      "Classification accuracy of test samples of character X is: 0.0%\n",
      "Classification accuracy of test samples of character T is: 40.0%\n",
      "Classification accuracy of test samples of character + is: 66.66666666666666%\n",
      "Classification accuracy of test samples of character N is: 0.0%\n",
      "Classification accuracy of test samples of character V is: 100.0%\n",
      "Classification accuracy of test samples of character 4 is: 46.666666666666664%\n"
     ]
    }
   ],
   "source": [
    "# Load training and testing data:\n",
    "useprint = True\n",
    "train_data, test_data, labels = dataprep(\"database_inc_sampchar\", useprint=useprint, shuffle=True, max_labels=0, max_samples=0, nr_test=15)\n",
    "\n",
    "# Evaluate trained model:\n",
    "acc, res_labl_list = hmm_test(hmm_best, test_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- RESULTS: ---------------- \n",
      "\n",
      " Character:  A\n",
      "Number of states:  2\n",
      "Test accuracy:  1.0 and resulting labels:  ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "Training accuracy: (log) -4.052334597750156\n",
      "\n",
      " Character:  C\n",
      "Number of states:  3\n",
      "Test accuracy:  0.0 and resulting labels:  ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', '4', 'A', 'A', 'A', 'A', 'A']\n",
      "Training accuracy: (log) -9.292675948675688\n",
      "\n",
      " Character:  K\n",
      "Number of states:  4\n",
      "Test accuracy:  0.3333333333333333 and resulting labels:  ['K', 'A', 'A', 'C', 'K', 'K', 'V', 'A', 'K', 'A', 'A', 'A', 'A', 'K', 'A']\n",
      "Training accuracy: (log) -5.4944826015051005\n",
      "\n",
      " Character:  P\n",
      "Number of states:  4\n",
      "Test accuracy:  0.06666666666666667 and resulting labels:  ['A', 'A', 'A', 'A', 'A', 'P', 'K', 'A', 'K', 'A', 'A', 'A', 'K', 'A', 'K']\n",
      "Training accuracy: (log) -5.242833590817606\n",
      "\n",
      " Character:  X\n",
      "Number of states:  5\n",
      "Test accuracy:  0.0 and resulting labels:  ['V', 'V', 'V', 'V', 'T', 'V', '+', 'V', 'V', 'A', 'T', 'V', 'V', '+', 'V']\n",
      "Training accuracy: (log) -3.3573299447649863\n",
      "\n",
      " Character:  T\n",
      "Number of states:  2\n",
      "Test accuracy:  0.4 and resulting labels:  ['T', '+', '+', 'T', 'T', 'T', '+', 'T', '+', '+', '+', '+', '+', 'T', '+']\n",
      "Training accuracy: (log) -2.9430099320301912\n",
      "\n",
      " Character:  +\n",
      "Number of states:  2\n",
      "Test accuracy:  0.6666666666666666 and resulting labels:  ['+', '+', '+', '+', 'T', '+', '+', '+', 'T', 'T', '+', '+', 'V', 'T', '+']\n",
      "Training accuracy: (log) -3.2437808840597953\n",
      "\n",
      " Character:  N\n",
      "Number of states:  2\n",
      "Test accuracy:  0.0 and resulting labels:  ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'C', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "Training accuracy: (log) -6.9612591364299785\n",
      "\n",
      " Character:  V\n",
      "Number of states:  2\n",
      "Test accuracy:  1.0 and resulting labels:  ['V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V', 'V']\n",
      "Training accuracy: (log) -3.123520914739744\n",
      "\n",
      " Character:  4\n",
      "Number of states:  2\n",
      "Test accuracy:  0.4666666666666667 and resulting labels:  ['K', 'A', 'C', 'A', '4', 'C', '4', '4', '4', 'A', 'A', 'A', '4', '4', '4']\n",
      "Training accuracy: (log) -4.538749031880217\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------- RESULTS: ---------------- \")\n",
    "for k in range(len(labels)):\n",
    "    print(\"\\n Character: \", labels[k])\n",
    "    print(\"Number of states: \", len(hmm_best[k].q))\n",
    "    print(\"Test accuracy: \",acc[k], \"and resulting labels: \",res_labl_list[k])\n",
    "    print(\"Training accuracy: (log)\", train_acc[k])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
