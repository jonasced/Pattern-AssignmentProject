{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c12b9b74",
   "metadata": {},
   "source": [
    "# Project test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deff7e25",
   "metadata": {},
   "source": [
    "In this assignment, we are going to improve our codes in PattRecClasses and implement forward algorithm inside MarkovChain code as well as functions such as logprob and prob in Guassian in order to generate proper input values for forward algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6521ec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from CharacterFeatureExtractor import featureExtractor\n",
    "from DrawCharacter import DrawCharacter\n",
    "from PattRecClasses import HMM_TA \n",
    "from hmm_gen import hmm_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e7a1b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Multivariate Gaussian Distribution Class\n",
    "'''\n",
    "class multigaussD:\n",
    "    mean = np.array([0])\n",
    "    cov = np.array([[0]])\n",
    "    def __init__(self, mu, C):\n",
    "        if C.shape[0] is not C.shape[1]:\n",
    "            print(\"error, non-square covariance matrix supplied\")\n",
    "            return\n",
    "        if mu.shape[0] is not C.shape[0]:\n",
    "            print(\"error, mismatched mean vector and covariance matrix dimensions\")\n",
    "            return\n",
    "        self.mean = mu\n",
    "        if np.where(np.diag(C)==0)[0].shape[0] != 0:\n",
    "            C += np.diagflat(np.ones(C.shape[0])/10000)\n",
    "        C[np.isnan(C)]=1\n",
    "        self.cov = C\n",
    "        return\n",
    "    def random(self, num):\n",
    "        return np.random.multivariate_normal(self.mean, self.cov, num)\n",
    "    def rand(self):\n",
    "        return np.random.multivariate_normal(self.mean, self.cov, 1)[0]\n",
    "    def likelihood(self, X):\n",
    "        p = scipy.stats.multivariate_normal(self.mean, self.cov, 1)\n",
    "        pd = p.pdf(X)\n",
    "        return pd\n",
    "    def loghood(self, X):\n",
    "        return np.log(self.likelihood(X))\n",
    "    def getmean(self):\n",
    "        return self.mean\n",
    "    def getcov(self):\n",
    "        return self.cov\n",
    "    \n",
    "def prob(x, B):\n",
    "    T = x.shape[0]\n",
    "    N = B.shape[0]\n",
    "    res = np.zeros((T, N))\n",
    "    for i in range(T):\n",
    "        for j in range(N):\n",
    "            res[i,j] = B[j].likelihood(x[i])\n",
    "    scaled = np.zeros(res.shape)\n",
    "    for i in range(scaled.shape[0]):\n",
    "        for j in range(scaled.shape[1]):\n",
    "            scaled[i, j] = res[i,j]/np.amax(res[i])\n",
    "    return res, scaled\n",
    "\n",
    "\n",
    "def logprob(x, B):\n",
    "    res, scaled = prob(x,B)\n",
    "    return np.log(res), np.log(scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9edbfab",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d54fc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'C', 'K', 'P', 'X', 'T', '+', 'N', 'V', '4']\n"
     ]
    }
   ],
   "source": [
    "### data prep\n",
    "db_name = \"database_inc_sampchar\"\n",
    "data_features = pd.read_pickle(r'data/' + db_name + '_features.cdb')\n",
    "data_labels = pd.read_pickle(r'data/' + db_name + '_labels.cdb')\n",
    "\n",
    "# data_features[k][r] == np.array (ndim, t); K (number of letters) of R samples with Tr individual lengths\n",
    "# print((data_features[1][1].shape))\n",
    "print(data_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c6da825",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------------ CHARACTER A ------------\n",
      "Training data 15\n",
      "Testing data 5\n",
      "Running the Baum Welch Algorithm...\n",
      "Estimated a:\n",
      "[1. 0.]\n",
      "\n",
      "Estimated A:\n",
      "[[9.54268293e-001 4.57317073e-002]\n",
      " [2.26047316e-110 1.00000000e+000]]\n",
      "\n",
      "Estimated means:\n",
      "[[ 9.88769976e+00  1.30798728e-02]\n",
      " [ 3.73023796e+01 -9.37072087e+00]]\n",
      "\n",
      "Estimated covariances:\n",
      "[[[2.61255325e+00 1.94903689e+01]\n",
      "  [1.94903689e+01 4.02569848e+03]]\n",
      "\n",
      " [[2.14526648e+01 1.08125268e+01]\n",
      "  [1.08125268e+01 2.36881247e+02]]]\n",
      "c is [1.         0.95426829 0.95426829 0.95426829 0.95426829 0.95426829\n",
      " 0.95426829 0.95426829 0.95426829 0.95426829 0.95426829 0.95426829\n",
      " 0.95426829 0.95426829 0.95426831 0.95426829 0.95426829 0.95426829\n",
      " 0.95426829 0.9542683  0.95426829 0.95426829 0.95426829 0.95426831\n",
      " 0.95426828 0.95426829 0.95426829 0.95426829 0.04573171 1.\n",
      " 1.         1.         1.         1.         1.        ]\n",
      "c is [1.         0.95426829 0.95426829 0.95426829 0.95426829 0.95426829\n",
      " 0.95426829 0.95426829 0.9542683  0.95426829 0.95426829 0.95426829\n",
      " 0.04573171 1.         1.         1.        ]\n",
      "c is [1.         0.95426829 0.95426829 0.95426829 0.95426829 0.95426829\n",
      " 0.95426829 0.95426829 0.95426829 0.95426829 0.95426829 0.95426829\n",
      " 0.95426829 0.95426829 0.95426829 0.95426829 0.9542683  0.95426831\n",
      " 0.95426827 0.95426829 0.95426829 0.95426829 0.95426829 0.95426829\n",
      " 0.95426829 0.95426829 0.95426829 0.95426829 0.95426829 0.95426829\n",
      " 0.04573171 1.         1.         1.         1.        ]\n",
      "c is [1.         0.95426829 0.95426829 0.95426829 0.95426829 0.95426829\n",
      " 0.95426829 0.95426829 0.95426829 0.95426829 0.95426829 0.95426829\n",
      " 0.95426829 0.95426829 0.95426829 0.95426829 0.95426829 0.95426829\n",
      " 0.95426829 0.95426829 0.95426829 0.95426829 0.95426829 0.04573171\n",
      " 1.         1.         1.         1.        ]\n",
      "c is [1.         0.95426829 0.95426829 0.95426829 0.95426829 0.95426829\n",
      " 0.95426829 0.95426829 0.95426829 0.95426829 0.95426829 0.95426829\n",
      " 0.95426829 0.95426829 0.95426829 0.95426829 0.95426829 0.95426829\n",
      " 0.95426829 0.95426829 0.95426829 0.95426829 0.95426829 0.95426829\n",
      " 0.95426829 0.95426829 0.95426829 0.95426829 0.95426829 0.9542683\n",
      " 0.95426829 0.04573171 1.         1.         1.         1.\n",
      " 1.        ]\n",
      "[-4.34884468790894, -3.5998780035435693, -4.442465524763081, -4.114792596715795, -4.4892759421243555]\n",
      "Avg probability over test samples is 0.015009809108921381\n",
      "\n",
      "\n",
      "------------ CHARACTER C ------------\n",
      "Training data 15\n",
      "Testing data 5\n",
      "Running the Baum Welch Algorithm...\n",
      "Estimated a:\n",
      "[0.0664154  0.18470864 0.74887596]\n",
      "\n",
      "Estimated A:\n",
      "[[3.22286245e-01 6.77705208e-01 8.54704148e-06]\n",
      " [1.60066582e-34 8.78638620e-01 1.21361380e-01]\n",
      " [2.18451085e-01 1.89576469e-02 7.62591268e-01]]\n",
      "\n",
      "Estimated means:\n",
      "[[  9.68212632  -2.16728861]\n",
      " [  9.84980758  52.21979462]\n",
      " [  9.8269757  -33.28533283]]\n",
      "\n",
      "Estimated covariances:\n",
      "[[[2.00633682e-01 1.34806422e+00]\n",
      "  [1.34806422e+00 9.05808048e+00]]\n",
      "\n",
      " [[1.68820757e+00 5.06327423e+00]\n",
      "  [5.06327423e+00 7.73808588e+02]]\n",
      "\n",
      " [[1.85944743e+00 4.84968471e+00]\n",
      "  [4.84968471e+00 6.15128834e+02]]]\n",
      "c is [0.71176948 0.27990475 0.76593734 0.87560221 0.87774936 0.87859366\n",
      " 0.8786313  0.87863866 0.12149011 0.76197906 0.76289245 0.76428038\n",
      " 0.76471673 0.2175075  0.3222634 ]\n",
      "c is [0.75281751 0.7603554  0.76300224 0.76322106 0.76325564 0.2179571\n",
      " 0.6773694  0.88067963 0.87698199 0.87864218 0.878396   0.87856715\n",
      " 0.87861422 0.87862894 0.8786355  0.87863704 0.12139337 0.76243127\n",
      " 0.76259871 0.76258814 0.76277524 0.76284128 0.76305722 0.21834111\n",
      " 0.32226667 0.32228625 0.49990855 0.89381344 0.87239262]\n",
      "c is [0.34922658 0.50400598 0.82959766 0.87617321 0.87829025 0.87862484\n",
      " 0.87863867 0.8786376  0.87863865 0.12187892 0.76029123 0.76304784\n",
      " 0.76258482 0.21850311 0.32221457 0.49935742]\n",
      "c is [0.76127966 0.75435723 0.21842244 0.11360722 0.27566203 0.10587212\n",
      " 0.58026928 0.89643692 0.86408208 0.87526639 0.8786379  0.87860913\n",
      " 0.87841553 0.87862417 0.87863756 0.12156557 0.76195663 0.76315538\n",
      " 0.76215255 0.76360152 0.76359944 0.76622956 0.31602951 0.09431334\n",
      " 0.82291035]\n",
      "c is [0.75769229 0.75651239 0.76318966 0.21818087 0.32224804 0.17114848\n",
      " 0.76812955 0.82846174 0.8405927  0.83821025 0.86795376 0.88004993\n",
      " 0.87624922 0.87840202 0.87861094 0.87862509 0.87863867 0.8786376\n",
      " 0.12143893 0.76218731 0.76259884 0.76259046 0.76260586 0.76263225\n",
      " 0.76270277 0.76337023 0.76387272 0.76305111 0.76260594 0.21815862\n",
      " 0.07630629 0.00250807 0.67975302 0.87503582 0.87862988 0.87672752\n",
      " 0.87863979]\n",
      "[-8.37677903048268, -12.908594004587046, -8.971711465480894, -16.799922303935634, -22.906968326288577]\n",
      "Avg probability over test samples is 8.375414967177502e-07\n",
      "\n",
      "\n",
      "------------ CHARACTER K ------------\n",
      "Training data 15\n",
      "Testing data 5\n",
      "Running the Baum Welch Algorithm...\n",
      "Estimated a:\n",
      "[1. 0. 0.]\n",
      "\n",
      "Estimated A:\n",
      "[[8.94366197e-001 1.05633803e-001 0.00000000e+000]\n",
      " [4.32323046e-180 9.32908110e-001 6.70918900e-002]\n",
      " [0.00000000e+000 4.28610898e-031 1.00000000e+000]]\n",
      "\n",
      "Estimated means:\n",
      "[[ 10.2599167   59.0917643 ]\n",
      " [ 45.32684655  28.8255996 ]\n",
      " [ 41.24877876 -32.89980076]]\n",
      "\n",
      "Estimated covariances:\n",
      "[[[ 1.01745267e+00 -2.45506220e+00]\n",
      "  [-2.45506220e+00  3.65564483e+03]]\n",
      "\n",
      " [[ 2.64049867e+01 -8.95293998e+01]\n",
      "  [-8.95293998e+01  1.03214626e+03]]\n",
      "\n",
      " [[ 7.50856694e+00  4.78327396e+00]\n",
      "  [ 4.78327396e+00  1.72177726e+02]]]\n",
      "c is [1.         0.8943662  0.8943662  0.8943662  0.8943662  0.8943662\n",
      " 0.8943662  0.8943662  0.8943662  0.8943662  0.1056338  0.93290811\n",
      " 0.93290814 0.93290822 0.932908   0.93290826 0.93290793 0.93291057\n",
      " 0.93290565 0.08276346 0.82466263 0.9985203  0.99999551 1.\n",
      " 1.         1.         1.         1.        ]\n",
      "c is [1.         0.8943662  0.8943662  0.8943662  0.8943662  0.8943662\n",
      " 0.8943662  0.1056338  0.93290827 0.93290799 0.93290807 0.93290812\n",
      " 0.93290815 0.93291079 0.93290878 0.95335809 0.20730644 0.55530185\n",
      " 0.92736026 0.91783758 0.99311936]\n",
      "c is [1.         0.8943662  0.8943663  0.89436609 0.8943662  0.8943662\n",
      " 0.89436619 0.8943662  0.8943662  0.8943662  0.8943662  0.1056338\n",
      " 0.93290812 0.9329081  0.93290811 0.93290811 0.93290812 0.93290816\n",
      " 0.93290805 0.93290811 0.93290811 0.93290811 0.93624275 0.92987414\n",
      " 0.93264834 0.93306056 0.93275563 0.93287988 0.93290811 0.93294477\n",
      " 0.9329307 ]\n",
      "c is [1.         0.8943662  0.8943662  0.8943662  0.8943662  0.89436632\n",
      " 0.8943662  0.89436608 0.8943662  0.8943662  0.8943662  0.8943662\n",
      " 0.1056338  0.93290811 0.93290811 0.93290888 0.93290748 0.93290797\n",
      " 0.93290816 0.93290807 0.9329081  0.93290811 0.93290811 0.93290851\n",
      " 0.06716109 0.99906159 0.99998415 0.99999982 1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.        ]\n",
      "c is [1.         0.8943662  0.8943662  0.8943662  0.8943662  0.1056338\n",
      " 0.93290818 0.93290837 0.93290811 0.93301528 0.93280096 0.93290778\n",
      " 0.08193136 0.83390583 0.99729311 0.99956947 0.99995743]\n",
      "[-6.494159988030597, -5.781370802723365, -4.683634101354579, -6.941366534046529, -5.797720141714178]\n",
      "Avg probability over test samples is 0.0026329501969972204\n"
     ]
    }
   ],
   "source": [
    "\"\"\" hmm_learned, training_accuracy =  hmm_train(train_data, labels)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "hm_learn = hmm_gen(data_features, 10, print=False)\n",
    "train_data = []\n",
    "test_data = []\n",
    "train_results = []\n",
    "\n",
    "\n",
    "\n",
    "for char in range(3):  # len(data_features)\n",
    "    print(\"\\n\")\n",
    "    print(\"------------ CHARACTER\", data_labels[char], \"------------\")\n",
    "    # Data preprocessing \n",
    "    obs = data_features[char]\n",
    "    # oos_obs = data_features[char-1]\n",
    "    \n",
    "    # obsTA = np.array([ hm_learn.rand(100)[0] for _ in range(10) ])\n",
    "    # print(type(obsTA))\n",
    "    # print(obsTA[1].shape) == (100,2)\n",
    "    # Our data has format (2,15) ! Transpose all datapoints\n",
    "    for i in range(len(obs)):\n",
    "        obs[i] = np.transpose(obs[i])\n",
    "    \n",
    "    #data_features[char] = obs  # so we do not have to reinvert the data later\n",
    "    \n",
    "    #for i in range(len(oos_obs)):\n",
    "    #    oos_obs[i] = np.transpose(oos_obs[i])\n",
    "\n",
    "    # Data information\n",
    "    \"\"\"\n",
    "    print(len(obs))\n",
    "    print(obs[len(obs) - 1].shape)\n",
    "    print(type(obs))\n",
    "    print(obs[1])\n",
    "    \"\"\"\n",
    "\n",
    "    # Divide data into training and testing\n",
    "    \n",
    "    train_obs = obs[0:len(obs)-5]\n",
    "    test_obs = obs[len(obs)-5:len(obs)]\n",
    "    \n",
    "    print(\"Training data\", len(train_obs))\n",
    "    print(\"Testing data\", len(test_obs))\n",
    "    \n",
    "    # Training\n",
    "    print(\"Running the Baum Welch Algorithm...\")\n",
    "    hm_learn[char].baum_welch(train_obs, 20, prin=1, uselog=False)\n",
    "\n",
    "    \n",
    "    # Testing on out of sample and test obs\n",
    "    \n",
    "    #a, c = hm_learn[char].alphahat(oos_obs[2])\n",
    "    #print(\"Prob oos\", c)\n",
    "    lprob_list = []\n",
    "    \n",
    "    \n",
    "    # Testing! \n",
    "    \n",
    "    for test in test_obs:\n",
    "        a, c = hm_learn[char].alphahat(test)\n",
    "        print(\"c is\", c)\n",
    "        clog = np.log(c)\n",
    "        lprob = np.sum(np.array(clog))\n",
    "        lprob_list += [lprob]\n",
    "        \n",
    "    print(lprob_list)\n",
    "    \n",
    "    avg = np.mean(np.array(lprob_list))\n",
    "    print(\"Avg probability over test samples is\", np.exp(avg))\n",
    "    train_results += [avg]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
